{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4310761,"sourceType":"datasetVersion","datasetId":2539169}],"dockerImageVersionId":30498,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# **Imports**","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom glob import glob\nimport time\nimport json\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nfrom datetime import datetime \nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, UpSampling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import models, layers, regularizers\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport glob\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-19T10:46:43.276129Z","iopub.execute_input":"2024-04-19T10:46:43.276930Z","iopub.status.idle":"2024-04-19T10:46:52.925402Z","shell.execute_reply.started":"2024-04-19T10:46:43.276896Z","shell.execute_reply":"2024-04-19T10:46:52.924344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Variables**","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = (256, 256)\n\ntrain_files = glob.glob('../input/brain-tumor-segmentation/images/*.png')\nmask_files = glob.glob('../input/brain-tumor-segmentation/masks/*.png')\n\nEPOCHS = 80\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:46:52.927531Z","iopub.execute_input":"2024-04-19T10:46:52.928166Z","iopub.status.idle":"2024-04-19T10:46:54.328541Z","shell.execute_reply.started":"2024-04-19T10:46:52.928137Z","shell.execute_reply":"2024-04-19T10:46:54.327757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Visualization**","metadata":{}},{"cell_type":"code","source":"def diagnosis(mask):\n    value = np.max(cv2.imread(mask))\n    return '1' if value > 0 else '0'\ndf = pd.DataFrame({\"image_path\": train_files,\n                    \"mask_path\": mask_files,\n                    \"diagnosis\": [diagnosis(x) for x in mask_files]})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:46:54.329643Z","iopub.execute_input":"2024-04-19T10:46:54.329916Z","iopub.status.idle":"2024-04-19T10:47:25.508859Z","shell.execute_reply.started":"2024-04-19T10:46:54.329892Z","shell.execute_reply":"2024-04-19T10:47:25.507912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_positive = df[df['diagnosis']=='1'].sample(5).values\n\ndef show_data(df, positive=True):\n    images = []\n    masks = []\n    for data in df:\n        img = cv2.imread(data[0])\n        mask = cv2.imread(data[1])\n        images.append(img)\n        masks.append(mask)\n    images = np.hstack(np.array(images))\n    masks = np.hstack(np.array(masks))\n    \n    fig = plt.figure(figsize=(25,25))\n    if positive:\n        grid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.5)\n    else:\n        grid = ImageGrid(fig, 111, nrows_ncols=(2,1), axes_pad=0.5)\n    grid[0].imshow(images)\n    grid[0].set_title('Photo', fontsize=15)\n    grid[0].axis('off')\n    grid[1].imshow(masks)\n    grid[1].set_title('Mask', fontsize=15)\n    grid[1].axis('off')\n    if positive:\n        grid[2].imshow(images)\n        grid[2].imshow(masks, alpha=0.4)\n        grid[2].set_title('Photo and mask', fontsize=15)\n        grid[2].axis('off')\n        \nshow_data(df_positive)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:47:25.509990Z","iopub.execute_input":"2024-04-19T10:47:25.510244Z","iopub.status.idle":"2024-04-19T10:47:27.921708Z","shell.execute_reply.started":"2024-04-19T10:47:25.510222Z","shell.execute_reply":"2024-04-19T10:47:27.920827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Splitting data into train and test** ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, test_size=0.15)\ndf_train, df_val = train_test_split(df_train, test_size=0.15)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:47:27.924663Z","iopub.execute_input":"2024-04-19T10:47:27.925202Z","iopub.status.idle":"2024-04-19T10:47:27.934751Z","shell.execute_reply.started":"2024-04-19T10:47:27.925169Z","shell.execute_reply":"2024-04-19T10:47:27.933886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nlabels = ['Training', 'Validation', 'Testing']\nsizes = [2213, 391, 460]\ncolors = ['blue', 'green', 'orange']\nplt.bar(labels, sizes, color=colors)\nplt.title('Dataset 2')\nfor i, v in enumerate(sizes):\n    plt.text(i, v + 30, str(v), ha='center')\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:47:27.935939Z","iopub.execute_input":"2024-04-19T10:47:27.936280Z","iopub.status.idle":"2024-04-19T10:47:28.159451Z","shell.execute_reply.started":"2024-04-19T10:47:27.936254Z","shell.execute_reply":"2024-04-19T10:47:28.158477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Augmentation & Processing**","metadata":{}},{"cell_type":"code","source":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"grayscale\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"image_path\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask_path\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img / 255.\n    mask = mask / 255.\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:47:28.160685Z","iopub.execute_input":"2024-04-19T10:47:28.160972Z","iopub.status.idle":"2024-04-19T10:47:28.171125Z","shell.execute_reply.started":"2024-04-19T10:47:28.160933Z","shell.execute_reply":"2024-04-19T10:47:28.170113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator_args = dict(rotation_range=0.1,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            fill_mode='nearest')\n\ntrain_gen = train_generator(df_train, BATCH_SIZE, train_generator_args, target_size=IMAGE_SIZE)\n\nval_gen = train_generator(df_val, BATCH_SIZE, dict(), target_size=IMAGE_SIZE)\n\ntest_gen = train_generator(df_test, BATCH_SIZE, dict(), target_size=IMAGE_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:47:28.172507Z","iopub.execute_input":"2024-04-19T10:47:28.172848Z","iopub.status.idle":"2024-04-19T10:47:28.184907Z","shell.execute_reply.started":"2024-04-19T10:47:28.172821Z","shell.execute_reply":"2024-04-19T10:47:28.183930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Dice and IoU Loss Functions**","metadata":{}},{"cell_type":"code","source":"smooth=1.\n\ndef dice_coef(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    union = K.sum(y_true) + K.sum(y_pred)\n    return (2.0 * intersection + smooth) / (union + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef bce_dice_loss(y_true, y_pred):\n    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return jac\n\ndef iou_loss(y_true, y_pred):\n    return 1 - iou(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T12:05:20.535409Z","iopub.execute_input":"2024-04-19T12:05:20.536138Z","iopub.status.idle":"2024-04-19T12:05:20.544030Z","shell.execute_reply.started":"2024-04-19T12:05:20.536102Z","shell.execute_reply":"2024-04-19T12:05:20.543085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Building Model : UNet**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Dropout, SeparableConv2D\n\ndef conv_block1(inputs, filters, dropout_rate=0.1):\n    x = SeparableConv2D(filters, (3, 3), padding='same')(inputs)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    x = SeparableConv2D(filters, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    if dropout_rate > 0:\n        x = Dropout(dropout_rate)(x)\n    return x\n\ndef encoder_block1(inputs, filters, dropout_rate=0.1):\n    x = conv_block1(inputs, filters, dropout_rate)\n    p = MaxPooling2D(pool_size=(2, 2))(x)\n    return x, p\n\ndef decoder_block1(inputs, filters, concat_layer, dropout_rate=0.1):\n    x = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(inputs)\n    x = concatenate([x, concat_layer])\n    x = conv_block1(x, filters, dropout_rate)\n    return x\n\ndef unet(input_shape, dropout_rate=0.1):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block1(inputs, 32, dropout_rate)\n    s2, p2 = encoder_block1(p1, 64, dropout_rate)\n    s3, p3 = encoder_block1(p2, 128, dropout_rate)\n    s4, p4 = encoder_block1(p3, 256, dropout_rate)\n\n    b1 = conv_block1(p4, 512, dropout_rate)\n\n    d1 = decoder_block1(b1, 256, s4, dropout_rate)\n    d2 = decoder_block1(d1, 128, s3, dropout_rate)\n    d3 = decoder_block1(d2, 64, s2, dropout_rate)\n    d4 = decoder_block1(d3, 32, s1, dropout_rate)\n\n    outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"UNet\")\n    return model\n\nunet_model = unet((256, 256, 1))\nunet_model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T12:16:07.834689Z","iopub.execute_input":"2024-04-19T12:16:07.835105Z","iopub.status.idle":"2024-04-19T12:16:08.684592Z","shell.execute_reply.started":"2024-04-19T12:16:07.835073Z","shell.execute_reply":"2024-04-19T12:16:08.678691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train the Model**","metadata":{}},{"cell_type":"code","source":"opt = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-7, amsgrad=False)\nunet_model.compile(optimizer=opt, loss=bce_dice_loss, metrics=[\"accuracy\", iou, dice_coef])\n\ncallbacks = [ModelCheckpoint('unet.hdf5', verbose=0, save_best_only=True),\n             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-11),\n             EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n\nhistory_unet = unet_model.fit(train_gen,\n                              steps_per_epoch=len(df_train) / BATCH_SIZE, \n                              epochs=EPOCHS, \n                              callbacks=callbacks,\n                              validation_data=val_gen,\n                              validation_steps=len(df_val) / BATCH_SIZE)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-19T12:16:13.580557Z","iopub.execute_input":"2024-04-19T12:16:13.581457Z","iopub.status.idle":"2024-04-19T14:19:48.391835Z","shell.execute_reply.started":"2024-04-19T12:16:13.581399Z","shell.execute_reply":"2024-04-19T14:19:48.391005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Evaluation**","metadata":{}},{"cell_type":"code","source":"model = load_model('unet.hdf5', custom_objects={'bce_dice_loss': bce_dice_loss, 'accuracy': \"accuracy\", 'iou': iou, 'dice_coef': dice_coef})\nresults = unet_model.evaluate(test_gen, steps=len(df_test) / BATCH_SIZE)\nprint(\"Loss:\", results[0])\nprint(\"Accuracy:\", results[1])\nprint(\"IoU Score:\", results[2])\nprint(\"Dice Score:\", results[3])","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:19:48.393600Z","iopub.execute_input":"2024-04-19T14:19:48.393913Z","iopub.status.idle":"2024-04-19T14:19:53.804081Z","shell.execute_reply.started":"2024-04-19T14:19:48.393885Z","shell.execute_reply":"2024-04-19T14:19:53.803111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_dict = history_unet.history\npd.DataFrame.from_dict(history_dict).to_csv('history_unet.csv', index = False)\nhistory_unet_df = pd.read_csv('history_unet.csv')\n\n# Set the height of each subplot\nfig, axs = plt.subplots(nrows=4, ncols=1, figsize=(8, 20))\n\n# Adjust the space between subplots\nplt.subplots_adjust(hspace=0.5)\n\n# Plot the loss\naxs[0].plot(history_unet_df['loss'], 'b-', label='Training Loss')\naxs[0].plot(history_unet_df['val_loss'], 'r-', label='Validation Loss')\naxs[0].set_xlabel('Epochs')\naxs[0].set_ylabel('Loss')\naxs[0].legend(loc='best')\n\n# Plot the accuracy\naxs[1].plot(history_unet_df['accuracy'], 'b-', label='Training Accuracy')\naxs[1].plot(history_unet_df['val_accuracy'], 'r-', label='Validation Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Accuracy')\naxs[1].legend(loc='best')\n\n# Plot the IOU\naxs[2].plot(history_unet_df['iou'], 'b-', label='Training IOU')\naxs[2].plot(history_unet_df['val_iou'], 'r-', label='Validation IOU')\naxs[2].set_xlabel('Epochs')\naxs[2].set_ylabel('IOU')\naxs[2].legend(loc='best')\n\n# Plot the dice coefficient\naxs[3].plot(history_unet_df['dice_coef'], 'b-', label='Training Dice Coefficient')\naxs[3].plot(history_unet_df['val_dice_coef'], 'r-', label='Validation Dice Coefficient')\naxs[3].set_xlabel('Epochs')\naxs[3].set_ylabel('Dice Coefficient')\naxs[3].legend(loc='best')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:19:53.805414Z","iopub.execute_input":"2024-04-19T14:19:53.805794Z","iopub.status.idle":"2024-04-19T14:19:54.706868Z","shell.execute_reply.started":"2024-04-19T14:19:53.805761Z","shell.execute_reply":"2024-04-19T14:19:54.705984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Test the model with an image**","metadata":{}},{"cell_type":"code","source":"for i in range(10):  \n    # Select a random image from the test set\n    index = np.random.randint(1, len(df_test.index))\n\n    # Load the image and preprocess it\n    img = cv2.imread(df_test['image_path'].iloc[index], cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img, IMAGE_SIZE)\n    img = img / 255\n    img = img[:, :, np.newaxis]\n    img = np.expand_dims(img, axis=0)\n\n    # Measure the inference time for UNet\n    start_time = time.time()\n    pred_unet = unet_model.predict(img)\n    end_time = time.time()\n    unet_inference_time = (end_time - start_time) * 1000\n\n    # Plot the original image and masks, as well as the predictions\n    plt.figure(figsize=(8, 4))\n    plt.subplot(1, 3, 1)\n    plt.imshow(np.squeeze(img), cmap='gray') \n    plt.title('Image')\n    plt.subplot(1, 3, 2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])), cmap='gray')  \n    plt.title('Ground Truth')\n    plt.subplot(1, 3, 3)\n    plt.imshow(np.squeeze(pred_unet) > .5, cmap='gray')  \n    plt.title('UNet Prediction')\n    plt.show()\n    \n    # Print the inference time for UNet\n    print(f'UNet Inference Time: {unet_inference_time:.4f} ms')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:19:54.709244Z","iopub.execute_input":"2024-04-19T14:19:54.709608Z","iopub.status.idle":"2024-04-19T14:20:01.383988Z","shell.execute_reply.started":"2024-04-19T14:19:54.709575Z","shell.execute_reply":"2024-04-19T14:20:01.383006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Highlighted Tumor**","metadata":{}},{"cell_type":"code","source":"# Load the model\nmodel_path = '/kaggle/working/unet.hdf5'\nmodel = load_model(model_path, compile=False)\n\ndef highlight_tumor(image_path, model):\n    # Read the image\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (256, 256))\n    image = image / 255.0  # Normalize the image\n\n    # Expand dimensions to match model input shape\n    image = np.expand_dims(image, axis=(0, -1))\n\n    # Perform segmentation\n    mask = model.predict(image)\n\n    # Threshold the mask\n    threshold = 0.5\n    mask_binary = (mask > threshold).astype(np.uint8)\n\n    # Convert the original image to RGB (for visualization purposes)\n    original_image_rgb = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\n    # Resize the mask to match the size of the original image\n    highlight_mask_resized = cv2.resize(mask_binary[0], (original_image_rgb.shape[1], original_image_rgb.shape[0]))\n\n    # Create a mask to highlight the tumor region in red\n    highlight_mask = cv2.cvtColor(highlight_mask_resized, cv2.COLOR_GRAY2RGB)\n    highlight_mask[:, :, 0] = np.where(highlight_mask[:, :, 0] > 0, 255, 0)  # Set red channel to 255 where tumor is present\n    highlight_mask[:, :, 1] = 0  # Set green channel to 0\n    highlight_mask[:, :, 2] = 0  # Set blue channel to 0\n\n    # Combine the original image with the highlight mask\n    highlighted_image = cv2.addWeighted(original_image_rgb, 0.7, highlight_mask, 0.3, 0)\n\n    # Display the highlighted image\n    plt.imshow(highlighted_image)\n    plt.title('Highlighted Tumor')\n    plt.axis('off')\n    plt.show()\n\n# Example usage:\nimage_path = '/kaggle/input/brain-tumor-segmentation/images/1.png'  # Update with the path to your image file\nhighlight_tumor(image_path, model)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T14:20:01.385146Z","iopub.execute_input":"2024-04-19T14:20:01.385427Z","iopub.status.idle":"2024-04-19T14:20:02.805732Z","shell.execute_reply.started":"2024-04-19T14:20:01.385401Z","shell.execute_reply":"2024-04-19T14:20:02.804750Z"},"trusted":true},"execution_count":null,"outputs":[]}]}